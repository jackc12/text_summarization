{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pour butter mixture popcorn mixture .</td>\n",
       "      <td>mix thoroughly .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drizzle honey top bananas .</td>\n",
       "      <td>would like also add sprinkle cinnamon well .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>create code conduct .</td>\n",
       "      <td>first need come code conduct .  employees need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apply mixture rubbing alcohol dish soap .</td>\n",
       "      <td>mix three parts liquid dish soap together one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>let hair airdry .</td>\n",
       "      <td>frequent use blow dryers flat irons hair curle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     headline  \\\n",
       "0      pour butter mixture popcorn mixture .    \n",
       "1                drizzle honey top bananas .    \n",
       "2                      create code conduct .    \n",
       "3  apply mixture rubbing alcohol dish soap .    \n",
       "4                          let hair airdry .    \n",
       "\n",
       "                                                text  \n",
       "0                                  mix thoroughly .   \n",
       "1      would like also add sprinkle cinnamon well .   \n",
       "2  first need come code conduct .  employees need...  \n",
       "3  mix three parts liquid dish soap together one ...  \n",
       "4  frequent use blow dryers flat irons hair curle...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../processed_data/test.csv', encoding='utf-8').dropna().reset_index(drop=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depending upon case may need use one three layers gripit create tight fit . \n",
      "turn test ensure stays . \n"
     ]
    }
   ],
   "source": [
    "x = data['text']\n",
    "y = data['headline']\n",
    "print(x[50],y[50],sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(text, summary, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(summary)\n",
    "        output_lang = Lang(text)\n",
    "    else:\n",
    "        input_lang = Lang(text)\n",
    "        output_lang = Lang(summary)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 136798 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "0                                         mix thoroughly . \n",
      "1             would like also add sprinkle cinnamon well . \n",
      "2         first need come code conduct .  employees need...\n",
      "3         mix three parts liquid dish soap together one ...\n",
      "4         frequent use blow dryers flat irons hair curle...\n",
      "5         hoover clean kitchen make beds get everything ...\n",
      "6         case users access webpage except ones allowed ...\n",
      "7         place elastic part balloon one side straw .  t...\n",
      "8         gta v game definitely suitable minors prompted...\n",
      "9         accepting nurses hospitals clinics want conduc...\n",
      "10                            connect end bracelet cclip . \n",
      "11        typing sudo cp hosts etchosts .  prompted pass...\n",
      "12        start playing dog spray taste deterrent areas ...\n",
      "13        cannot make friends move drastic measures .  o...\n",
      "14        say hello name  would like volunteer  .  happy...\n",
      "15        write list damaged property .  list helpful ne...\n",
      "16        try separate two equal parts .  put first bunc...\n",
      "17        need 1 cup superfine sugar 6 tablespoons butte...\n",
      "18               paperback nicely protected time want be . \n",
      "19        italian meetings dominated agenda indeed may e...\n",
      "20        exceptions rule liion batteries  suffer memory...\n",
      "21                                find people party hats . \n",
      "22        use method using formula fnfn1fn2displaystyle ...\n",
      "23        read consumer reviews truck combo alarm system...\n",
      "24        wear tuckedin shirt almost always accompany be...\n",
      "25        hide icons desktop using terminal commands .  ...\n",
      "26        carefully lift container holding wax double bo...\n",
      "27        f  files directory output merged together new ...\n",
      "28        letters people known least two years .  proofr...\n",
      "29        people large stacks cash make notes serial num...\n",
      "                                ...                        \n",
      "136768       entire surface salad covered lines toppings . \n",
      "136769    conceptually calculating laplace transform fun...\n",
      "136770    purpose notepad interview jot important inform...\n",
      "136771    sleep interrupted various external factors may...\n",
      "136772    using clean hands mix butter pieces flour mixt...\n",
      "136773    want write title ink first time .  write penci...\n",
      "136774    recess lunch perfect time talk .  eat chat tog...\n",
      "136775    use roomtemperature water aged left sitting op...\n",
      "136776    ask someone else give opinion layout content f...\n",
      "136777    consider using last entry outline highlights s...\n",
      "136778    rogaine ingredient called minoxidil helps stim...\n",
      "136779                   attach small fine nozzle piping . \n",
      "136780    frequent usage map need keyboard shortcut acce...\n",
      "136781    going get anything written constantly interrup...\n",
      "136782    healthy option sweeten tea go fruit .  try add...\n",
      "136783    plenty great playgrounds along waterfront .  k...\n",
      "136784    take tweezers gently pluck hair inside ear .  ...\n",
      "136785    dogs current incontinence leaving mess skin it...\n",
      "136786    get cover saved place top pie .  get aluminum ...\n",
      "136787    want tousled look gently tug outer loops dutch...\n",
      "136788    bookshelf tab left takes crafting interface . ...\n",
      "136789    leave lip balm plain add flavor 6 12 drops ess...\n",
      "136790                                    take 5 minutes . \n",
      "136791    place chicken breast large bowl sprinkle  cup ...\n",
      "136792    start sternum layer hide muscle gives space gu...\n",
      "136793    older centrifuges may feature make sure rotor ...\n",
      "136794    turtle get vitamins nutrients needs provide we...\n",
      "136795    emotional appeals powerful appeals particularl...\n",
      "136796    event created visit events menu .  event page ...\n",
      "136797    although email address already includes name e...\n",
      "Name: text, Length: 136798, dtype: object 90477\n",
      "0                    pour butter mixture popcorn mixture . \n",
      "1                              drizzle honey top bananas . \n",
      "2                                    create code conduct . \n",
      "3                apply mixture rubbing alcohol dish soap . \n",
      "4                                        let hair airdry . \n",
      "5                                                tidy house\n",
      "6         set strict internet surfing limit could choose...\n",
      "7         secure balloon flexible drinking straw rubber ...\n",
      "8                                            confirm age . \n",
      "9           choose available position interview facility . \n",
      "10                                          connect ends . \n",
      "11              copy file hosts top system etchosts file . \n",
      "12                   use taste deterrent keep dog biting . \n",
      "13                               ignore person hostility . \n",
      "14                either call person wait connected them . \n",
      "15                                      create inventory . \n",
      "16                   shake extra water adding watercress . \n",
      "17                                    gather ingredients . \n",
      "18                                            end result . \n",
      "19                      ready less structure may used to . \n",
      "20        memory effect using old laptop want prevent me...\n",
      "21                                       go around jamaa . \n",
      "22        sum previous two numbers find given number fib...\n",
      "23                                             go online . \n",
      "24                                              put belt . \n",
      "25                        hide rest icons using terminal . \n",
      "26                                         pour wax jars . \n",
      "27        command prompt open pointed directory text fil...\n",
      "28        gather two three letters recommendation profes...\n",
      "29                        always report large sums money . \n",
      "                                ...                        \n",
      "136768    line blue cheese roquefort crumbles next avoca...\n",
      "136769    substitute function definition laplace transfo...\n",
      "136770                  take notes important information . \n",
      "136771                      look external factors habits . \n",
      "136772     add grated butter bowl sifted dry ingredients . \n",
      "136773                                         map first . \n",
      "136774                                         catch can . \n",
      "136775    water hoya plants potting soil becomes almost ...\n",
      "136776                                  get help need it . \n",
      "136777                  finish summer journal end summer . \n",
      "136778                                 try using rogaine . \n",
      "136779           place custard mixture pastry piping bag . \n",
      "136780                          create keyboard shortcut . \n",
      "136781                             minimize distractions . \n",
      "136782                    try fresh fruit fruit products . \n",
      "136783                                          fit play . \n",
      "136784                            tweeze inside dog ears . \n",
      "136785                             consider dogs hygiene . \n",
      "136786                                        secure pie . \n",
      "136787                            fluff braid up desired . \n",
      "136788                                tap bookshelf icon . \n",
      "136789                     consider adding essential oil . \n",
      "136790       remove dough bag knead floured board smooth . \n",
      "136791                 clean chicken baking soda vinegar . \n",
      "136792                       make first incision sternum . \n",
      "136793    open lid rotor completely stopped . many moder...\n",
      "136794                           supplement diet calcium . \n",
      "136795          stoke passions audience emotional appeal . \n",
      "136796                                      manage event . \n",
      "136797                                     add signature . \n",
      "Name: headline, Length: 136798, dtype: object 33162\n",
      "['taking extermination job yourself make sure use approved rat poison rodent bait available home supply stores .  carefully follow usage directions precautions advised manufacturer . many forms bait come installed premade secure containers .  place near suspected rats .  rodents enter container eat bait die .  poisons often recommended use buildings .  rats may eat bait die decompose hardtoreach space like interior wall . ', 'use lethal poisons control rat populations . ']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData( x, y , False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_forcing_ratio = 0.5\n",
    "# def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "#     encoder_hidden = encoder.initHidden()\n",
    "\n",
    "#     encoder_optimizer.zero_grad()\n",
    "#     decoder_optimizer.zero_grad()\n",
    "\n",
    "#     input_length = input_tensor.size(0)\n",
    "#     target_length = target_tensor.size(0)\n",
    "\n",
    "#     encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "#     loss = 0\n",
    "\n",
    "#     for ei in range(input_length):\n",
    "#         encoder_output, encoder_hidden = encoder(\n",
    "#             input_tensor[ei], encoder_hidden)\n",
    "#         encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "#     decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "#     decoder_hidden = encoder_hidden\n",
    "\n",
    "#     use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "#     if use_teacher_forcing:\n",
    "#         # Teacher forcing: Feed the target as the next input\n",
    "#         for di in range(target_length):\n",
    "#             decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "#                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "#             loss += criterion(decoder_output, target_tensor[di])\n",
    "#             decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "#     else:\n",
    "#         # Without teacher forcing: use its own predictions as the next input\n",
    "#         for di in range(target_length):\n",
    "#             decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "#                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "#             topv, topi = decoder_output.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "#             loss += criterion(decoder_output, target_tensor[di])\n",
    "#             if decoder_input.item() == EOS_token:\n",
    "#                 break\n",
    "\n",
    "#     loss.backward()\n",
    "\n",
    "#     encoder_optimizer.step()\n",
    "#     decoder_optimizer.step()\n",
    "\n",
    "#     return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import math\n",
    "\n",
    "# def asMinutes(s):\n",
    "#     m = math.floor(s / 60)\n",
    "#     s -= m * 60\n",
    "#     return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "# def timeSince(since, percent):\n",
    "#     now = time.time()\n",
    "#     s = now - since\n",
    "#     es = s / (percent)\n",
    "#     rs = es - s\n",
    "#     return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "#     print(\"Training....\")\n",
    "#     start = time.time()\n",
    "#     plot_losses = []\n",
    "#     print_loss_total = 0  # Reset every print_every\n",
    "#     plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "#     encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "#     decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "#     training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "#                       for i in range(n_iters)]\n",
    "#     criterion = nn.NLLLoss()\n",
    "\n",
    "#     for iter in range(1, n_iters + 1):\n",
    "#         if iter% 1000 == 0:\n",
    "#             print(iter,\"/\",n_iters + 1)\n",
    "#         training_pair = training_pairs[iter - 1]\n",
    "#         input_tensor = training_pair[0]\n",
    "#         target_tensor = training_pair[1]\n",
    "\n",
    "#         loss = train(input_tensor, target_tensor, encoder,\n",
    "#                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "#         print_loss_total += loss\n",
    "#         plot_loss_total += loss\n",
    "\n",
    "#         if iter % print_every == 0:\n",
    "#             print_loss_avg = print_loss_total / print_every\n",
    "#             print_loss_total = 0\n",
    "#             print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "#                                          iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "#         if iter % plot_every == 0:\n",
    "#             plot_loss_avg = plot_loss_total / plot_every\n",
    "#             plot_losses.append(plot_loss_avg)\n",
    "#             plot_loss_total = 0\n",
    "\n",
    "#     showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAll(encoder, decoder):\n",
    "    predictions, actuals = [], []\n",
    "    for i in range(50000):\n",
    "        pair = random.choice(pairs)\n",
    "        actuals.append(pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        predictions.append(output_sentence.replace('<EOS>', '.'))\n",
    "    with open('predictions', 'w') as p, open('actuals', 'w') as a:\n",
    "        p.write('\\n'.join(predictions).replace('<EOS>', '.'))\n",
    "        a.write('\\n'.join(actuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pair in pairs:\n",
    "#     print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 300\n",
    "encoder1 = EncoderRNN(299436, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, 88783, dropout_p=0.1).to(device)\n",
    "\n",
    "# trainIters(encoder1, attn_decoder1, n_iters=175000, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(encoder1.state_dict(), './enc_1.w')\n",
    "# torch.save(attn_decoder1.state_dict(), './att_1.w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder1.load_state_dict(torch.load('enc_epoch=175000', map_location=torch.device('cpu')))\n",
    "attn_decoder1.load_state_dict(torch.load('att_epoch=175000', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateAll(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
